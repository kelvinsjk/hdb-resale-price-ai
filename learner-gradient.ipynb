{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# clean up data: area, date, floor, price\n",
    "def load_csv():\n",
    "  return pd.read_csv('./data/2305_3rm_woodlands.csv')\n",
    "def price_cleanup(df):\n",
    "  df['price'] = df.price.apply(lambda x:float(x.replace('$','').replace(',','')) if isinstance(x,str) else x)\n",
    "  return df\n",
    "def area_cleanup(df):\n",
    "  df['area'] = df.area.str.split('\\n',expand=True)[0].astype(float) if df.area.dtype != 'float64' else df.area\n",
    "  return df  \n",
    "def date_cleanup(df):\n",
    "  df['date'] = pd.to_datetime(df.date, format=\"%m/%d/%y\")\n",
    "  df['date'] = df.date.apply(lambda x:float(x.toordinal()) if not isinstance(x,float) else x)\n",
    "  return df\n",
    "floor_dict = { f'0{i*3+1} to 0{i*3+3}' if i < 3 else f'{i*3+1} to {i*3+3}': i*3+2  for i in range(11)  }\n",
    "def floor_cleanup(df):\n",
    "  df['floor'] = df.floor.apply(lambda x:float(floor_dict[x]) if isinstance(x,str) else x)\n",
    "  return df\n",
    "\n",
    "def load_and_cleanup():\n",
    "  df = load_csv()\n",
    "  price_cleanup(df)\n",
    "  area_cleanup(df)\n",
    "  date_cleanup(df)\n",
    "  floor_cleanup(df)\n",
    "  df.drop([\"block\", \"street\", \"lease\"], axis=1, inplace = True)\n",
    "  return df\n",
    "\n",
    "def get_xy():\n",
    "  df = load_and_cleanup()\n",
    "  y = torch.tensor(df.price)\n",
    "  df['date'] = df.date - 693595\n",
    "  means = df.mean()\n",
    "  stds = df.std()\n",
    "  df = (df-means)/stds\n",
    "  xs = torch.tensor(df.drop(\"price\", axis=1).values)\n",
    "  return (xs, y, means, stds)\n",
    "\n",
    "def f(x, params, bias):\n",
    "  return torch.sum(x*params, 1)+bias\n",
    "def f1(x,params,bias):\n",
    "  return torch.sum(x*params)+bias\n",
    "\n",
    "def mse(preds, targets):\n",
    "  return ((preds-targets)**2).mean()\n",
    "\n",
    "def loss(x, params, bias, targets):\n",
    "  return mse(f(x, params,bias), targets)\n",
    "\n",
    "def grad(xrow,params,bias,target):\n",
    "  return -2*xrow*(target-f1(xrow,params,bias))\n",
    "\n",
    "def grad_bias(xrow,params,bias,target):\n",
    "  return-2*(target-f1(xrow,params,bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize params and bias\n",
    "(xs, y, means, stds) = get_xy()\n",
    "\n",
    "# take mean as starting point since other params are normalized\n",
    "bias = y.mean()\n",
    "# bias_step should be different because it is not normalized\n",
    "# random initial params\n",
    "params = torch.rand(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration -1: loss $53364.45496608305\n",
      "tensor(31506.2002, dtype=torch.float64)\n",
      "tensor(22515.1017, dtype=torch.float64)\n",
      "tensor(19244.7106, dtype=torch.float64)\n",
      "tensor(18135.4988, dtype=torch.float64)\n",
      "tensor(17757.4424, dtype=torch.float64)\n",
      "tensor(17622.8531, dtype=torch.float64)\n",
      "Iteration 6: loss $17622.853125920512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(372774.9663, dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialize params and bias\n",
    "(xs, y, means, stds) = get_xy()\n",
    "\n",
    "# take mean as starting point since other params are normalized\n",
    "bias = y.mean()\n",
    "# bias_step should be different because it is not normalized\n",
    "# random initial params\n",
    "params = torch.rand(4)\n",
    "\n",
    "bias_step =   1e-3\n",
    "params_step = 1e-3\n",
    "\n",
    "## random stepper: takes a random step, and move if the loss is lower\n",
    "curr_loss = loss(xs,params,bias,y)\n",
    "print(f\"Iteration -1: loss ${curr_loss.sqrt()}\")    \n",
    "n = 6\n",
    "for i in range(n):\n",
    "  for i in range(len(xs)):\n",
    "    params = params - grad(xs[i], params, bias, y[i])*params_step\n",
    "    bias = bias - grad_bias(xs[i], params, bias, y[i])*bias_step  \n",
    "  print(loss(xs,params,bias,y).sqrt())\n",
    "\n",
    "curr_loss = loss(xs,params,bias,y)\n",
    "print(f\"Iteration {n}: loss ${curr_loss.sqrt()}\")\n",
    "params\n",
    "bias\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc2819e0cd58e12e49d4aa9b793031ae2fcdc5314c5c901672ba6897274f5c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
