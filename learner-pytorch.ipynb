{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# clean up data: area, date, floor, price\n",
    "def load_csv():\n",
    "  return pd.read_csv('./data/2305_3rm_woodlands.csv')\n",
    "def price_cleanup(df):\n",
    "  df['price'] = df.price.apply(lambda x:float(x.replace('$','').replace(',','')) if isinstance(x,str) else x)\n",
    "  return df\n",
    "def area_cleanup(df):\n",
    "  df['area'] = df.area.str.split('\\n',expand=True)[0].astype(float) if df.area.dtype != 'float64' else df.area\n",
    "  return df  \n",
    "def date_cleanup(df):\n",
    "  df['date'] = pd.to_datetime(df.date, format=\"%m/%d/%y\")\n",
    "  df['date'] = df.date.apply(lambda x:float(x.toordinal()) if not isinstance(x,float) else x)\n",
    "  return df\n",
    "floor_dict = { f'0{i*3+1} to 0{i*3+3}' if i < 3 else f'{i*3+1} to {i*3+3}': i*3+2  for i in range(11)  }\n",
    "def floor_cleanup(df):\n",
    "  df['floor'] = df.floor.apply(lambda x:float(floor_dict[x]) if isinstance(x,str) else x)\n",
    "  return df\n",
    "\n",
    "def load_and_cleanup():\n",
    "  df = load_csv()\n",
    "  price_cleanup(df)\n",
    "  area_cleanup(df)\n",
    "  date_cleanup(df)\n",
    "  floor_cleanup(df)\n",
    "  df.drop([\"block\", \"street\", \"lease\"], axis=1, inplace = True)\n",
    "  return df\n",
    "\n",
    "def get_xy():\n",
    "  df = load_and_cleanup()\n",
    "  y = torch.tensor(df.price)[:,None]\n",
    "  df['date'] = df.date - 693595\n",
    "  means = df.mean()\n",
    "  stds = df.std()\n",
    "  df = (df-means)/stds\n",
    "  df['bias'] = 1\n",
    "  xs = torch.tensor(df.drop(\"price\", axis=1).values).float()\n",
    "  return (xs, y, means, stds, df)\n",
    "\n",
    "(xs, y, means, stds, df) = get_xy()\n",
    "\n",
    "\n",
    "def f(params):\n",
    "  return (xs @ params) + y.mean()\n",
    "def mse(params):\n",
    "  return (torch.square(f(params)-y)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss53364.62395804597 loss rate 0.1\n",
      "loss43321.32189362336 loss rate 0.1\n",
      "loss27389.331112736567 loss rate 0.1\n",
      "loss25776.145884948168 loss rate 0.01\n",
      "loss24045.88069043632 loss rate 0.01\n",
      "loss22328.92215681267 loss rate 0.01\n",
      "loss20781.04895108481 loss rate 0.01\n",
      "loss19572.880896797327 loss rate 0.01\n",
      "loss19474.682245904605 loss rate 0.001\n",
      "loss19376.561349671447 loss rate 0.001\n",
      "loss19279.15177017224 loss rate 0.001\n",
      "loss19183.07229833393 loss rate 0.001\n",
      "loss19088.933331998247 loss rate 0.001\n",
      "loss18997.320467620008 loss rate 0.001\n",
      "loss18988.117969904204 loss rate 0.0001\n",
      "loss18978.544156445558 loss rate 0.0001\n",
      "loss18968.599918415348 loss rate 0.0001\n",
      "loss18958.29351878958 loss rate 0.0001\n",
      "loss18947.628244695177 loss rate 0.0001\n",
      "loss18936.61189129994 loss rate 0.0001\n",
      "loss18925.247234493894 loss rate 0.0001\n",
      "loss18913.542841785908 loss rate 0.0001\n",
      "loss18901.50483452154 loss rate 0.0001\n",
      "loss18889.137212655467 loss rate 0.0001\n",
      "loss18876.44813587793 loss rate 0.0001\n",
      "loss18863.444274138743 loss rate 0.0001\n",
      "loss18850.13229408765 loss rate 0.0001\n",
      "loss18836.520728970387 loss rate 0.0001\n",
      "loss18822.61363583168 loss rate 0.0001\n",
      "loss18808.42259482843 loss rate 0.0001\n",
      "loss18793.950986357813 loss rate 0.0001\n",
      "loss18779.21027939247 loss rate 0.0001\n",
      "loss18764.20810291731 loss rate 0.0001\n",
      "loss18748.950166999824 loss rate 0.0001\n",
      "loss18733.446816437794 loss rate 0.0001\n",
      "loss18717.706299401136 loss rate 0.0001\n",
      "loss18701.737641346663 loss rate 0.0001\n",
      "loss18685.549024257714 loss rate 0.0001\n",
      "loss18669.149758617146 loss rate 0.0001\n",
      "loss18652.5482672692 loss rate 0.0001\n",
      "loss18635.75713535812 loss rate 0.0001\n",
      "loss18618.782162226624 loss rate 0.0001\n",
      "loss18601.634528489576 loss rate 0.0001\n",
      "loss18584.32336870316 loss rate 0.0001\n",
      "loss18566.85931400506 loss rate 0.0001\n",
      "loss18549.25314046566 loss rate 0.0001\n",
      "loss18531.512979998548 loss rate 0.0001\n",
      "loss18513.653162739018 loss rate 0.0001\n",
      "loss18495.677671909776 loss rate 0.0001\n",
      "loss18477.601225602433 loss rate 0.0001\n",
      "loss18459.43673825485 loss rate 0.0001\n",
      "loss18441.189444401534 loss rate 0.0001\n",
      "loss18422.87317003602 loss rate 0.0001\n",
      "loss18404.49971058443 loss rate 0.0001\n",
      "loss18386.077010756042 loss rate 0.0001\n",
      "loss18367.618163661195 loss rate 0.0001\n",
      "loss18349.135756037875 loss rate 0.0001\n",
      "loss18330.639157028527 loss rate 0.0001\n",
      "loss18312.13897183222 loss rate 0.0001\n",
      "loss18293.64768316172 loss rate 0.0001\n",
      "loss18275.177341275546 loss rate 0.0001\n",
      "loss18256.7369914169 loss rate 0.0001\n",
      "loss18238.33886563984 loss rate 0.0001\n",
      "loss18219.995686205646 loss rate 0.0001\n",
      "loss18201.717606751423 loss rate 0.0001\n",
      "loss18183.518087145647 loss rate 0.0001\n",
      "loss18165.406484222716 loss rate 0.0001\n",
      "loss18147.39504568462 loss rate 0.0001\n",
      "loss18129.494330939924 loss rate 0.0001\n",
      "loss18111.717431355588 loss rate 0.0001\n",
      "loss18094.074627050868 loss rate 0.0001\n",
      "loss18076.577319300275 loss rate 0.0001\n",
      "loss18059.237893998707 loss rate 0.0001\n",
      "loss18042.06712787927 loss rate 0.0001\n",
      "loss18025.074746308754 loss rate 0.0001\n",
      "loss18008.27284305066 loss rate 0.0001\n",
      "loss17991.675263335273 loss rate 0.0001\n",
      "loss17975.288305548722 loss rate 0.0001\n",
      "loss17959.125126970364 loss rate 0.0001\n",
      "loss17943.196733869187 loss rate 0.0001\n",
      "loss17927.512964055073 loss rate 0.0001\n",
      "loss17912.086308251037 loss rate 0.0001\n",
      "loss17896.925156389716 loss rate 0.0001\n",
      "loss17882.039568536722 loss rate 0.0001\n",
      "loss17867.441472224637 loss rate 0.0001\n",
      "loss17853.1395772987 loss rate 0.0001\n",
      "loss17839.14328454054 loss rate 0.0001\n",
      "loss17825.463614275817 loss rate 0.0001\n",
      "loss17812.11046523307 loss rate 0.0001\n",
      "loss17799.091651632727 loss rate 0.0001\n",
      "loss17786.416236313944 loss rate 0.0001\n",
      "loss17774.09430902685 loss rate 0.0001\n",
      "loss17762.134191187175 loss rate 0.0001\n",
      "loss17750.54302037237 loss rate 0.0001\n",
      "loss17739.331414029304 loss rate 0.0001\n",
      "loss17728.50567095322 loss rate 0.0001\n",
      "loss17718.074862911395 loss rate 0.0001\n",
      "loss17708.044064033744 loss rate 0.0001\n",
      "loss17698.423237384435 loss rate 0.0001\n",
      "loss17689.219876390496 loss rate 0.0001\n",
      "loss 17689.219876390496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0254e+04],\n",
       "        [ 1.0053e+04],\n",
       "        [ 4.6791e+04],\n",
       "        [ 1.0278e+04],\n",
       "        [-1.0977e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# initialize params\n",
    "params = torch.rand(5,1)\n",
    "params.requires_grad_()\n",
    "\n",
    "lr = 1e-1\n",
    "\n",
    "n = 100\n",
    "for i in range(n):\n",
    "  loss = mse(params)\n",
    "  loss.backward()\n",
    "  print(f'loss{loss.sqrt()} loss rate {lr}')\n",
    "  if (loss.sqrt() < 19000):\n",
    "    lr = 1e-4\n",
    "  elif (loss.sqrt() < 20000):\n",
    "    lr = 1e-3\n",
    "  elif (loss.sqrt() < 30000):\n",
    "    lr = 1e-2\n",
    "  with torch.no_grad():\n",
    "    #print(params)\n",
    "    params.sub_(params.grad * lr)\n",
    "    #print(params)\n",
    "    new_loss = mse(params)\n",
    "  if (new_loss > loss):\n",
    "    print(f'local min reached at {i}, {loss.sqrt()}')\n",
    "    params = params + params.grad * lr\n",
    "    break\n",
    "  #else:\n",
    "\n",
    "print(f'loss {loss.sqrt()}')\n",
    "params* y.std()\n",
    "params\n",
    "#y.mean()\n",
    "#f(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc2819e0cd58e12e49d4aa9b793031ae2fcdc5314c5c901672ba6897274f5c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
